{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9210126b68554b93ab919661ba56be3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bb5ad9cc8244eda954b2066a470dc8b",
              "IPY_MODEL_d524770a59774d44be67ee343c075d0e",
              "IPY_MODEL_5092d83e588644c7a9f8b0022e00db2f"
            ],
            "layout": "IPY_MODEL_1f0e7ce886b54e48822a2480b83d12f7"
          }
        },
        "9bb5ad9cc8244eda954b2066a470dc8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04c314673fae4584b25c2016138a8fed",
            "placeholder": "​",
            "style": "IPY_MODEL_857b0e3f3ea645b587536c0522379b44",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "d524770a59774d44be67ee343c075d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_396fe9db3c6244bf8603d63e0966d6b1",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8af896807a645f49e60f5ad2e4b888a",
            "value": 1000
          }
        },
        "5092d83e588644c7a9f8b0022e00db2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866d8f9e0f4945c19f2a2e848bf2c343",
            "placeholder": "​",
            "style": "IPY_MODEL_22681f521fd844c488e5673ac78f387e",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 15.5kB/s]"
          }
        },
        "1f0e7ce886b54e48822a2480b83d12f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c314673fae4584b25c2016138a8fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "857b0e3f3ea645b587536c0522379b44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "396fe9db3c6244bf8603d63e0966d6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8af896807a645f49e60f5ad2e4b888a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "866d8f9e0f4945c19f2a2e848bf2c343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22681f521fd844c488e5673ac78f387e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e879c87a94c44676b8568a099bfd60af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e1516b2efc140ecbf79a4b3df750a9d",
              "IPY_MODEL_97adefd2579f4003970c2128e7169680",
              "IPY_MODEL_cc8bdb2a014f4db5adaf8682bd98dc2e"
            ],
            "layout": "IPY_MODEL_7b1191fbfa5a4cae989c02f5df87f4a4"
          }
        },
        "2e1516b2efc140ecbf79a4b3df750a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b820896d1a204d1dae8d2982e7dfabc9",
            "placeholder": "​",
            "style": "IPY_MODEL_f191c9ccca02453091251e85234fe28a",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "97adefd2579f4003970c2128e7169680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b346c68e517a4d76aded2449cc6a6cda",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e31930218554c74b3898a3aeda9e1dd",
            "value": 513302779
          }
        },
        "cc8bdb2a014f4db5adaf8682bd98dc2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_183a53b90d81416e90ed0c1357bd7193",
            "placeholder": "​",
            "style": "IPY_MODEL_8529ab241fff489d8173626d680f2eeb",
            "value": " 513M/513M [00:03&lt;00:00, 142MB/s]"
          }
        },
        "7b1191fbfa5a4cae989c02f5df87f4a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b820896d1a204d1dae8d2982e7dfabc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f191c9ccca02453091251e85234fe28a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b346c68e517a4d76aded2449cc6a6cda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e31930218554c74b3898a3aeda9e1dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "183a53b90d81416e90ed0c1357bd7193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8529ab241fff489d8173626d680f2eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cea96d99634497eb8e7f1e05ddcc3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cda07d523bf49049fdde26305d3247e",
              "IPY_MODEL_980b083905e94c59bf4ebac4a06c6abe",
              "IPY_MODEL_b0d29107a63941b89a8a06f75388abcc"
            ],
            "layout": "IPY_MODEL_a7d5ca982f314ed2a8f4f23a53616d1e"
          }
        },
        "2cda07d523bf49049fdde26305d3247e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f93cb43e3bdf43f0985007e93df6b208",
            "placeholder": "​",
            "style": "IPY_MODEL_a7ca1113a8fa4588bbdecff46089a6d6",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "980b083905e94c59bf4ebac4a06c6abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_347d760cc56f4bf9ba00efe1fd78d09e",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed9336faaad645c893b0381d2d9c650d",
            "value": 2825034
          }
        },
        "b0d29107a63941b89a8a06f75388abcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5a4ca9dc2d449e9b9d15ac5dff27fbc",
            "placeholder": "​",
            "style": "IPY_MODEL_bb01e5bea6ae4ffb8ec3a50b873c2f0e",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 22.5MB/s]"
          }
        },
        "a7d5ca982f314ed2a8f4f23a53616d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f93cb43e3bdf43f0985007e93df6b208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7ca1113a8fa4588bbdecff46089a6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "347d760cc56f4bf9ba00efe1fd78d09e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9336faaad645c893b0381d2d9c650d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5a4ca9dc2d449e9b9d15ac5dff27fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb01e5bea6ae4ffb8ec3a50b873c2f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeonseong0917/NLP_study/blob/main/s_GPT3_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iymxoASh2gYS",
        "outputId": "052f06b8-95ce-416a-de7e-c795534ce6e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May  3 05:39:04 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z7hNUqqYIRW7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl1fCySKz9AP",
        "outputId": "ec52ee0a-6580-4ae5-b0fb-f5b7651e8f7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->accelerate) (1.3.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, accelerate\n",
            "Successfully installed accelerate-0.18.0 huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ChcZpL6W0T0L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Code Reference](https://velog.io/@gtpgg1013/kogpt-%ED%95%9C%EA%B5%AD%EC%96%B4-%EC%83%9D%EC%84%B1-GPT-3-%EB%AA%85%EB%AC%B8%EA%B0%80-%EB%82%A9%EC%8B%9C%EC%98%A4)\n",
        "\n",
        "[Code Reference2](https://littlefoxdiary.tistory.com/46)\n",
        "\n"
      ],
      "metadata": {
        "id": "ehXVWzRfICoi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Cyr1JaIzIBVf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THqfjTP5yymO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242,
          "referenced_widgets": [
            "9210126b68554b93ab919661ba56be3b",
            "9bb5ad9cc8244eda954b2066a470dc8b",
            "d524770a59774d44be67ee343c075d0e",
            "5092d83e588644c7a9f8b0022e00db2f",
            "1f0e7ce886b54e48822a2480b83d12f7",
            "04c314673fae4584b25c2016138a8fed",
            "857b0e3f3ea645b587536c0522379b44",
            "396fe9db3c6244bf8603d63e0966d6b1",
            "e8af896807a645f49e60f5ad2e4b888a",
            "866d8f9e0f4945c19f2a2e848bf2c343",
            "22681f521fd844c488e5673ac78f387e",
            "e879c87a94c44676b8568a099bfd60af",
            "2e1516b2efc140ecbf79a4b3df750a9d",
            "97adefd2579f4003970c2128e7169680",
            "cc8bdb2a014f4db5adaf8682bd98dc2e",
            "7b1191fbfa5a4cae989c02f5df87f4a4",
            "b820896d1a204d1dae8d2982e7dfabc9",
            "f191c9ccca02453091251e85234fe28a",
            "b346c68e517a4d76aded2449cc6a6cda",
            "2e31930218554c74b3898a3aeda9e1dd",
            "183a53b90d81416e90ed0c1357bd7193",
            "8529ab241fff489d8173626d680f2eeb",
            "6cea96d99634497eb8e7f1e05ddcc3a0",
            "2cda07d523bf49049fdde26305d3247e",
            "980b083905e94c59bf4ebac4a06c6abe",
            "b0d29107a63941b89a8a06f75388abcc",
            "a7d5ca982f314ed2a8f4f23a53616d1e",
            "f93cb43e3bdf43f0985007e93df6b208",
            "a7ca1113a8fa4588bbdecff46089a6d6",
            "347d760cc56f4bf9ba00efe1fd78d09e",
            "ed9336faaad645c893b0381d2d9c650d",
            "b5a4ca9dc2d449e9b9d15ac5dff27fbc",
            "bb01e5bea6ae4ffb8ec3a50b873c2f0e"
          ]
        },
        "id": "de-d84KbyfEN",
        "outputId": "5d59293d-137c-4955-8c3a-2d8db471e15f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9210126b68554b93ab919661ba56be3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e879c87a94c44676b8568a099bfd60af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.10.attn.masked_bias', 'lm_head.weight', 'transformer.h.3.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.2.attn.masked_bias']\n",
            "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cea96d99634497eb8e7f1e05ddcc3a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM \n",
        "\"\"\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]'\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  'kakaobrain/kogpt', revision='KoGPT6B-ryan1.5b-float16',  # or float32 version: revision=KoGPT6B-ryan1.5b\n",
        "  pad_token_id=tokenizer.eos_token_id,\n",
        "  torch_dtype='auto', low_cpu_mem_usage=True\n",
        ").to(device='cuda', non_blocking=True)\n",
        "_ = model.eval()\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFGPT2LMHeadModel\n",
        "from transformers import GPTJForCausalLM, AutoTokenizer\n",
        "model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')\n",
        "# tokenizer = AutoTokenizer.from_pretrained('MrBananaHuman/kogpt_6b_fp16', bos_token='[BOS]', eos_token='[EOS]', unk_token='[UNK]', pad_token='[PAD]', mask_token='[MASK]')\n",
        "\n",
        "# model = GPTJForCausalLM.from_pretrained('MrBananaHuman/kogpt_6b_fp16', pad_token_id=tokenizer.eos_token_id, torch_dtype='auto', low_cpu_mem_usage=True)\n",
        "# model.to('cuda', non_blocking=True)\n",
        "# _ = model.eval()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = '근육이 커지기 위해서는'"
      ],
      "metadata": {
        "id": "wnRqisEGfAvd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer.encode(sent)\n",
        "input_ids = tf.convert_to_tensor([input_ids])\n",
        "print(input_ids)\n",
        "output = model.generate(input_ids,\n",
        "                        max_length=128,\n",
        "                        repetition_penalty=2.0,\n",
        "                        use_cache=True)\n",
        "output_ids = output.numpy().tolist()[0]\n",
        "print(output_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnvr7xDGdEPW",
        "outputId": "009356f4-bec5-4b1d-8c3f-34f3a3e04cbc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[33245 10114 12748 11357]], shape=(1, 4), dtype=int32)\n",
            "[33245, 10114, 12748, 11357, 23879, 39306, 9684, 7884, 10211, 15177, 26421, 387, 17339, 7889, 9908, 15768, 6903, 15386, 8146, 12923, 9228, 18651, 42600, 9564, 17764, 9033, 9199, 14441, 7335, 8704, 12557, 32030, 9510, 18595, 9025, 10571, 25741, 10599, 13229, 9508, 7965, 8425, 33102, 9122, 21240, 9801, 32106, 13579, 12442, 13235, 19430, 8022, 12972, 9566, 11178, 9554, 24873, 7198, 9391, 12486, 8711, 9346, 7071, 36736, 9693, 12006, 9038, 10279, 36122, 9960, 8405, 10826, 18988, 25998, 9292, 7671, 9465, 7489, 9277, 10137, 9677, 9248, 9912, 12834, 11488, 13417, 7407, 8428, 8137, 9430, 14222, 11356, 10061, 9885, 19265, 9377, 20305, 7991, 9178, 9648, 9133, 10021, 10138, 30315, 21833, 9362, 9301, 9685, 11584, 9447, 42129, 10124, 7532, 17932, 47123, 37544, 9355, 15632, 9124, 10536, 13530, 12204, 9184, 36152, 9673, 9788, 9029, 11764]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(output_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "TqGAHakedP3H",
        "outputId": "58ba8b74-1c5d-41a1-c0d2-9e812831781e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'근육이 커지기 위해서는 무엇보다 규칙적인 생활습관이 중요하다.\\n특히, 아침식사는 단백질과 비타민이 풍부한 과일과 채소를 많이 섭취하는 것이 좋다.\\n또한 하루 30분 이상 충분한 수면을 취하는 것도 도움이 된다.\\n아침 식사를 거르지 않고 규칙적으로 운동을 하면 혈액순환에 도움을 줄 뿐만 아니라 신진대사를 촉진해 체내 노폐물을 배출하고 혈압을 낮춰준다.\\n운동은 하루에 10분 정도만 하는 게 좋으며 운동 후에는 반드시 스트레칭을 통해 근육량을 늘리고 유연성을 높여야 한다.\\n운동 후 바로 잠자리에 드는 것은 피해야 하며 특히 아침에 일어나면 몸이 피곤해지기 때문에 무리하게 움직이면 오히려 역효과가 날 수도 있다.\\n운동을'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_ids)\n",
        "top5 = tf.math.top_k(output.logits[0, -1], k=10000)\n",
        "print(type(top5))\n",
        "m=tokenizer.convert_ids_to_tokens(top5.indices.numpy())\n",
        "m=m[len(m)-6 :len(m)]\n",
        "print(m)\n",
        "# print(len(m))\n",
        "# for i in range(1,5):\n",
        "#   print(m[len(m)-i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mJMpKJZdVhR",
        "outputId": "86c9196d-5e95-4cfc-d5c8-221b6889694d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.ops.gen_nn_ops.TopKV2'>\n",
            "['▁화려', '▁73', '▁방법으로', '▁동전을', '▁들여', '▁자문']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "origin= '봄이 오면 나무에는 파릇파릇한 싹이 돋아나고, 천지에 생명력이 가득하여 우리를 설레게 한다.\\n봄을 맞이하여 우리도 새로운 학교와 학급에서 새 친구들과 함께하는 즐거운 국어 시간을 통해 문학의 아름다움을 즐길 줄 아는 사람으로 성장할 것이다'\n",
        "sent = \"나무에는\"\n",
        "input_ids = tokenizer.encode(sent)\n",
        "print(type(input_ids))\n",
        "print(input_ids)\n",
        "while len(input_ids) < 30:\n",
        "    output = model(np.array([input_ids]))\n",
        "    # Top 5의 단어들을 추출\n",
        "    top5 = tf.math.top_k(output.logits[0, -1], k=1000)\n",
        "    # top5=top5[len(top5)-5:len(top5)]\n",
        "    k=tokenizer.convert_ids_to_tokens(top5.indices.numpy())\n",
        "    k=k[len(k)-6 :len(k)]\n",
        "    \n",
        "    for i in range(len(k)):\n",
        "      k[i]=tokenizer.encode(k[i])\n",
        "    \n",
        "    # Top 5의 단어들 중 랜덤으로 다음 단어로 선택.\n",
        "    token_id = random.choice(k)\n",
        "    input_ids.append(token_id[0])\n",
        "\n",
        "tokenizer.decode(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "paWIPR3aevhT",
        "outputId": "9966fcb9-6212-4306-bbb5-be9e1607b117"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "[10221, 9052]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'나무에는 연못 위를 꿈 처음 견 분 드는 힘을 빚어 만들어진 슈퍼 그래 물이 촘촘 뿌리 있다. 여름철 수질  증 게 소식이 가득 있다는 집에 주인의 웃음을 받아야'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "origin= '봄이 오면 나무에는 파릇파릇한 싹이 돋아나고, 천지에 생명력이 가득하여 우리를 설레게 한다.\\n봄을 맞이하여 우리도 새로운 학교와 학급에서 새 친구들과 함께하는 즐거운 국어 시간을 통해 문학의 아름다움을 즐길 줄 아는 사람으로 성장할 것이다'\n",
        "origin=list(origin.split(\" \"))\n",
        "print(origin[0])\n",
        "res=[]\n",
        "for i in range(30):\n",
        "  sent=origin[i]\n",
        "  input_ids=tokenizer.encode(sent)\n",
        "  while len(input_ids) < 30:\n",
        "    output = model(np.array([input_ids]))\n",
        "    # Top 5의 단어들을 추출\n",
        "    top5 = tf.math.top_k(output.logits[0, -1], k=1000)\n",
        "    k=tokenizer.convert_ids_to_tokens(top5.indices.numpy())\n",
        "    # k=k[len(k)-6 :len(k)]\n",
        "    k=k[-5:]\n",
        "    \n",
        "    for i in range(len(k)):\n",
        "      k[i]=tokenizer.encode(k[i])\n",
        "    \n",
        "    # Top 5의 단어들 중 랜덤으로 다음 단어로 선택.\n",
        "    token_id = random.choice(k)\n",
        "    input_ids.append(token_id[0])\n",
        "\n",
        "  res.append(tokenizer.decode(input_ids))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztL0ODOfR8yY",
        "outputId": "ce19f9d6-e98e-4b67-d951-d58f69ce248a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "봄이\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6VOEu2iXY4R",
        "outputId": "0135a37c-5fe8-481d-a2db-cc0f2686b14d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['봄이 일본 국내에 조금 진정 거 능 영    라고 가서 일반 폰 소리에 섞인 혹은 알고 짠 잡 술 술이 없이 시간 짧게 바꿔 알고 비싼 태', '오면 찬 공해 서 치 주의 타이 같은 형태 소비 연료를 필요에 연관 규 작업 직전 자율 위험 관 원 하는데 있는데 법적 사례가 전부 는 형태가 학 상으로 탁', '나무에는 쌍          맞 츠 무지 치 채 먹으면 숨겨 말할 전 최 평론 문서 ; 브로 사무 화 J 중', '파릇파릇한 뒤 주름 죽은 형의 막 털을 맘 을 서늘 조각 납 룩 깊이 낼 동 석 앞에 뭉쳐 세월 본 자아 특유의 동작으로 호소 딱', \"싹이 마음 낸 빗 · 목재 등이 만나는 바깥'좌 생물 테크 이 심 ( 공룡 시대부터 20 호 식량 대부분이 소화 나간 관을 주입 스, 차량 플라스틱\", '돋아나고, 계절 전체의 구름이 윤곽을 돌아 공중에 덮어 베 밝 시는 꽃은 항 산으로 낮게 심어 보았을 먼 말이 얼어 다 복 받자 과 정이 결혼 마 치', '천지에 말 입 질 높여 필   족 하 차고 먹어 지니 좋고 속에 제일 행복한 양파 트 매운 증 살을 가두 하나 타고 너도  이겨 리', '생명력이 광 욱 일 사랑 되어 키워 목 주위에 깨끗한 염색 탈 신기 암 전이 레이저 반대 표면에 와 혼 전의 입술 껍질이 공기 중이 높아 프로 크라 간을', '가득하여 쓰러 버려 ~        😙 시간이 가게 길을 폴 다는 부끄러 니 담 세상이 유 가로 남은 집에서 그것도 곤 ', '우리를 매장 소 교환 무대로 부활      시키 ( 북미 맹 학생 극 교사 마이      😎 직접 고기 부탁']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(res)\n",
        "tokenizer2=Tokenizer()\n",
        "tokenizer2.fit_on_texts(res)\n",
        "t2_vocab_size=len(tokenizer2.word_index)+1\n",
        "print(t2_vocab_size)\n",
        "sequences = list()\n",
        "\n",
        "for sentence in res:\n",
        "\n",
        "    # 각 샘플에 대한 정수 인코딩\n",
        "    encoded = tokenizer2.texts_to_sequences([sentence])[0] \n",
        "    for i in range(1, len(encoded)):\n",
        "        sequence = encoded[:i+1]\n",
        "        sequences.append(sequence)\n",
        "\n",
        "print(sequences[:11])\n",
        "index_to_word = {}\n",
        "for key, value in tokenizer2.word_index.items(): # 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
        "    index_to_word[value] = key\n",
        "\n",
        "# print('빈도수 상위 580번 단어 : {}'.format(index_to_word[580]))\n",
        "max_len = max(len(l) for l in sequences)\n",
        "print('샘플의 최대 길이 : {}'.format(max_len))\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
        "# print(sequences[:3])\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:,:-1]\n",
        "y = sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=t2_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSj7BI6iX2XV",
        "outputId": "56a8536e-c42d-495a-a97e-0cdae1fb0f74"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "683\n",
            "[[73, 74], [73, 74, 4], [73, 74, 4, 75], [73, 74, 4, 75, 76], [73, 74, 4, 75, 76, 77], [73, 74, 4, 75, 76, 77, 78], [73, 74, 4, 75, 76, 77, 78, 79], [73, 74, 4, 75, 76, 77, 78, 79, 80], [73, 74, 4, 75, 76, 77, 78, 79, 80, 81], [73, 74, 4, 75, 76, 77, 78, 79, 80, 81, 82], [73, 74, 4, 75, 76, 77, 78, 79, 80, 81, 82, 83]]\n",
            "샘플의 최대 길이 : 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "embedding_dim = 10\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(t2_vocab_size, embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(t2_vocab_size, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyQRhshcfD7I",
        "outputId": "6892544f-7b7b-4137-db76-3b55f9734442"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "24/24 - 10s - loss: 6.5313 - accuracy: 0.0000e+00 - 10s/epoch - 400ms/step\n",
            "Epoch 2/200\n",
            "24/24 - 4s - loss: 6.5252 - accuracy: 0.0068 - 4s/epoch - 158ms/step\n",
            "Epoch 3/200\n",
            "24/24 - 3s - loss: 6.5177 - accuracy: 0.0081 - 3s/epoch - 124ms/step\n",
            "Epoch 4/200\n",
            "24/24 - 2s - loss: 6.4823 - accuracy: 0.0027 - 2s/epoch - 87ms/step\n",
            "Epoch 5/200\n",
            "24/24 - 6s - loss: 6.4064 - accuracy: 0.0109 - 6s/epoch - 229ms/step\n",
            "Epoch 6/200\n",
            "24/24 - 3s - loss: 6.2955 - accuracy: 0.0081 - 3s/epoch - 125ms/step\n",
            "Epoch 7/200\n",
            "24/24 - 2s - loss: 6.1562 - accuracy: 0.0095 - 2s/epoch - 96ms/step\n",
            "Epoch 8/200\n",
            "24/24 - 2s - loss: 6.0170 - accuracy: 0.0109 - 2s/epoch - 83ms/step\n",
            "Epoch 9/200\n",
            "24/24 - 1s - loss: 5.8826 - accuracy: 0.0109 - 505ms/epoch - 21ms/step\n",
            "Epoch 10/200\n",
            "24/24 - 1s - loss: 5.7498 - accuracy: 0.0095 - 713ms/epoch - 30ms/step\n",
            "Epoch 11/200\n",
            "24/24 - 1s - loss: 5.8121 - accuracy: 0.0122 - 1s/epoch - 46ms/step\n",
            "Epoch 12/200\n",
            "24/24 - 2s - loss: 5.6076 - accuracy: 0.0163 - 2s/epoch - 73ms/step\n",
            "Epoch 13/200\n",
            "24/24 - 1s - loss: 5.4784 - accuracy: 0.0136 - 1s/epoch - 44ms/step\n",
            "Epoch 14/200\n",
            "24/24 - 1s - loss: 5.3650 - accuracy: 0.0163 - 1s/epoch - 44ms/step\n",
            "Epoch 15/200\n",
            "24/24 - 1s - loss: 5.2588 - accuracy: 0.0149 - 950ms/epoch - 40ms/step\n",
            "Epoch 16/200\n",
            "24/24 - 1s - loss: 5.1668 - accuracy: 0.0217 - 1s/epoch - 44ms/step\n",
            "Epoch 17/200\n",
            "24/24 - 1s - loss: 5.0499 - accuracy: 0.0271 - 808ms/epoch - 34ms/step\n",
            "Epoch 18/200\n",
            "24/24 - 1s - loss: 5.0005 - accuracy: 0.0204 - 545ms/epoch - 23ms/step\n",
            "Epoch 19/200\n",
            "24/24 - 0s - loss: 4.9071 - accuracy: 0.0231 - 477ms/epoch - 20ms/step\n",
            "Epoch 20/200\n",
            "24/24 - 1s - loss: 4.7972 - accuracy: 0.0271 - 1s/epoch - 45ms/step\n",
            "Epoch 21/200\n",
            "24/24 - 1s - loss: 4.7155 - accuracy: 0.0339 - 932ms/epoch - 39ms/step\n",
            "Epoch 22/200\n",
            "24/24 - 0s - loss: 4.6360 - accuracy: 0.0448 - 194ms/epoch - 8ms/step\n",
            "Epoch 23/200\n",
            "24/24 - 1s - loss: 4.5105 - accuracy: 0.0611 - 745ms/epoch - 31ms/step\n",
            "Epoch 24/200\n",
            "24/24 - 0s - loss: 4.4862 - accuracy: 0.0543 - 475ms/epoch - 20ms/step\n",
            "Epoch 25/200\n",
            "24/24 - 0s - loss: 4.3561 - accuracy: 0.0814 - 429ms/epoch - 18ms/step\n",
            "Epoch 26/200\n",
            "24/24 - 1s - loss: 4.2845 - accuracy: 0.0828 - 1s/epoch - 45ms/step\n",
            "Epoch 27/200\n",
            "24/24 - 1s - loss: 4.2369 - accuracy: 0.0678 - 507ms/epoch - 21ms/step\n",
            "Epoch 28/200\n",
            "24/24 - 0s - loss: 4.1689 - accuracy: 0.0801 - 197ms/epoch - 8ms/step\n",
            "Epoch 29/200\n",
            "24/24 - 1s - loss: 4.2476 - accuracy: 0.0624 - 785ms/epoch - 33ms/step\n",
            "Epoch 30/200\n",
            "24/24 - 1s - loss: 4.0721 - accuracy: 0.0868 - 767ms/epoch - 32ms/step\n",
            "Epoch 31/200\n",
            "24/24 - 0s - loss: 3.9713 - accuracy: 0.1275 - 225ms/epoch - 9ms/step\n",
            "Epoch 32/200\n",
            "24/24 - 1s - loss: 3.9285 - accuracy: 0.1330 - 815ms/epoch - 34ms/step\n",
            "Epoch 33/200\n",
            "24/24 - 1s - loss: 3.9459 - accuracy: 0.1140 - 1s/epoch - 60ms/step\n",
            "Epoch 34/200\n",
            "24/24 - 1s - loss: 3.8423 - accuracy: 0.1316 - 1s/epoch - 46ms/step\n",
            "Epoch 35/200\n",
            "24/24 - 0s - loss: 3.7272 - accuracy: 0.1465 - 180ms/epoch - 7ms/step\n",
            "Epoch 36/200\n",
            "24/24 - 1s - loss: 3.6666 - accuracy: 0.1493 - 872ms/epoch - 36ms/step\n",
            "Epoch 37/200\n",
            "24/24 - 1s - loss: 3.8057 - accuracy: 0.1045 - 1s/epoch - 61ms/step\n",
            "Epoch 38/200\n",
            "24/24 - 1s - loss: 3.6796 - accuracy: 0.1588 - 1s/epoch - 46ms/step\n",
            "Epoch 39/200\n",
            "24/24 - 0s - loss: 3.6253 - accuracy: 0.1615 - 468ms/epoch - 20ms/step\n",
            "Epoch 40/200\n",
            "24/24 - 0s - loss: 3.5523 - accuracy: 0.1777 - 315ms/epoch - 13ms/step\n",
            "Epoch 41/200\n",
            "24/24 - 1s - loss: 3.5245 - accuracy: 0.1859 - 695ms/epoch - 29ms/step\n",
            "Epoch 42/200\n",
            "24/24 - 0s - loss: 3.3672 - accuracy: 0.2714 - 329ms/epoch - 14ms/step\n",
            "Epoch 43/200\n",
            "24/24 - 0s - loss: 3.3038 - accuracy: 0.2917 - 135ms/epoch - 6ms/step\n",
            "Epoch 44/200\n",
            "24/24 - 0s - loss: 3.2002 - accuracy: 0.3691 - 132ms/epoch - 5ms/step\n",
            "Epoch 45/200\n",
            "24/24 - 0s - loss: 3.1565 - accuracy: 0.3514 - 125ms/epoch - 5ms/step\n",
            "Epoch 46/200\n",
            "24/24 - 0s - loss: 3.0924 - accuracy: 0.3826 - 314ms/epoch - 13ms/step\n",
            "Epoch 47/200\n",
            "24/24 - 0s - loss: 3.0808 - accuracy: 0.3772 - 330ms/epoch - 14ms/step\n",
            "Epoch 48/200\n",
            "24/24 - 0s - loss: 3.0199 - accuracy: 0.4193 - 135ms/epoch - 6ms/step\n",
            "Epoch 49/200\n",
            "24/24 - 0s - loss: 2.9377 - accuracy: 0.4396 - 127ms/epoch - 5ms/step\n",
            "Epoch 50/200\n",
            "24/24 - 0s - loss: 2.9003 - accuracy: 0.4586 - 136ms/epoch - 6ms/step\n",
            "Epoch 51/200\n",
            "24/24 - 0s - loss: 2.8446 - accuracy: 0.4749 - 122ms/epoch - 5ms/step\n",
            "Epoch 52/200\n",
            "24/24 - 0s - loss: 2.8289 - accuracy: 0.4532 - 121ms/epoch - 5ms/step\n",
            "Epoch 53/200\n",
            "24/24 - 0s - loss: 3.0572 - accuracy: 0.2727 - 131ms/epoch - 5ms/step\n",
            "Epoch 54/200\n",
            "24/24 - 0s - loss: 2.9716 - accuracy: 0.3243 - 126ms/epoch - 5ms/step\n",
            "Epoch 55/200\n",
            "24/24 - 0s - loss: 2.7734 - accuracy: 0.4640 - 319ms/epoch - 13ms/step\n",
            "Epoch 56/200\n",
            "24/24 - 1s - loss: 2.6746 - accuracy: 0.5265 - 509ms/epoch - 21ms/step\n",
            "Epoch 57/200\n",
            "24/24 - 0s - loss: 2.5867 - accuracy: 0.5604 - 130ms/epoch - 5ms/step\n",
            "Epoch 58/200\n",
            "24/24 - 0s - loss: 2.5533 - accuracy: 0.5455 - 129ms/epoch - 5ms/step\n",
            "Epoch 59/200\n",
            "24/24 - 0s - loss: 2.6430 - accuracy: 0.4640 - 127ms/epoch - 5ms/step\n",
            "Epoch 60/200\n",
            "24/24 - 0s - loss: 2.5359 - accuracy: 0.4953 - 125ms/epoch - 5ms/step\n",
            "Epoch 61/200\n",
            "24/24 - 0s - loss: 2.4785 - accuracy: 0.5550 - 315ms/epoch - 13ms/step\n",
            "Epoch 62/200\n",
            "24/24 - 0s - loss: 2.4977 - accuracy: 0.5075 - 128ms/epoch - 5ms/step\n",
            "Epoch 63/200\n",
            "24/24 - 0s - loss: 2.5439 - accuracy: 0.4722 - 338ms/epoch - 14ms/step\n",
            "Epoch 64/200\n",
            "24/24 - 0s - loss: 2.4285 - accuracy: 0.5265 - 204ms/epoch - 9ms/step\n",
            "Epoch 65/200\n",
            "24/24 - 0s - loss: 2.3740 - accuracy: 0.5617 - 180ms/epoch - 8ms/step\n",
            "Epoch 66/200\n",
            "24/24 - 0s - loss: 2.2900 - accuracy: 0.6065 - 471ms/epoch - 20ms/step\n",
            "Epoch 67/200\n",
            "24/24 - 0s - loss: 2.2855 - accuracy: 0.5929 - 190ms/epoch - 8ms/step\n",
            "Epoch 68/200\n",
            "24/24 - 0s - loss: 2.2082 - accuracy: 0.6133 - 475ms/epoch - 20ms/step\n",
            "Epoch 69/200\n",
            "24/24 - 0s - loss: 2.2829 - accuracy: 0.5916 - 188ms/epoch - 8ms/step\n",
            "Epoch 70/200\n",
            "24/24 - 0s - loss: 2.3327 - accuracy: 0.5658 - 176ms/epoch - 7ms/step\n",
            "Epoch 71/200\n",
            "24/24 - 0s - loss: 2.2545 - accuracy: 0.5767 - 188ms/epoch - 8ms/step\n",
            "Epoch 72/200\n",
            "24/24 - 0s - loss: 2.7354 - accuracy: 0.3609 - 193ms/epoch - 8ms/step\n",
            "Epoch 73/200\n",
            "24/24 - 0s - loss: 2.4583 - accuracy: 0.4640 - 188ms/epoch - 8ms/step\n",
            "Epoch 74/200\n",
            "24/24 - 0s - loss: 2.2732 - accuracy: 0.5617 - 200ms/epoch - 8ms/step\n",
            "Epoch 75/200\n",
            "24/24 - 0s - loss: 2.1586 - accuracy: 0.6147 - 190ms/epoch - 8ms/step\n",
            "Epoch 76/200\n",
            "24/24 - 0s - loss: 2.6329 - accuracy: 0.3596 - 197ms/epoch - 8ms/step\n",
            "Epoch 77/200\n",
            "24/24 - 0s - loss: 2.2595 - accuracy: 0.5373 - 186ms/epoch - 8ms/step\n",
            "Epoch 78/200\n",
            "24/24 - 1s - loss: 2.0931 - accuracy: 0.6242 - 673ms/epoch - 28ms/step\n",
            "Epoch 79/200\n",
            "24/24 - 0s - loss: 1.9998 - accuracy: 0.6703 - 145ms/epoch - 6ms/step\n",
            "Epoch 80/200\n",
            "24/24 - 0s - loss: 1.9842 - accuracy: 0.6621 - 128ms/epoch - 5ms/step\n",
            "Epoch 81/200\n",
            "24/24 - 0s - loss: 1.8976 - accuracy: 0.6961 - 133ms/epoch - 6ms/step\n",
            "Epoch 82/200\n",
            "24/24 - 0s - loss: 1.8510 - accuracy: 0.7205 - 126ms/epoch - 5ms/step\n",
            "Epoch 83/200\n",
            "24/24 - 0s - loss: 1.8545 - accuracy: 0.7178 - 324ms/epoch - 14ms/step\n",
            "Epoch 84/200\n",
            "24/24 - 0s - loss: 1.8212 - accuracy: 0.7083 - 136ms/epoch - 6ms/step\n",
            "Epoch 85/200\n",
            "24/24 - 0s - loss: 1.7706 - accuracy: 0.7354 - 318ms/epoch - 13ms/step\n",
            "Epoch 86/200\n",
            "24/24 - 0s - loss: 1.7662 - accuracy: 0.7286 - 321ms/epoch - 13ms/step\n",
            "Epoch 87/200\n",
            "24/24 - 0s - loss: 1.7170 - accuracy: 0.7517 - 126ms/epoch - 5ms/step\n",
            "Epoch 88/200\n",
            "24/24 - 0s - loss: 1.6866 - accuracy: 0.7585 - 126ms/epoch - 5ms/step\n",
            "Epoch 89/200\n",
            "24/24 - 0s - loss: 1.6786 - accuracy: 0.7585 - 128ms/epoch - 5ms/step\n",
            "Epoch 90/200\n",
            "24/24 - 0s - loss: 1.6592 - accuracy: 0.7408 - 337ms/epoch - 14ms/step\n",
            "Epoch 91/200\n",
            "24/24 - 0s - loss: 1.6591 - accuracy: 0.7436 - 128ms/epoch - 5ms/step\n",
            "Epoch 92/200\n",
            "24/24 - 0s - loss: 1.6183 - accuracy: 0.7503 - 325ms/epoch - 14ms/step\n",
            "Epoch 93/200\n",
            "24/24 - 0s - loss: 1.5496 - accuracy: 0.7761 - 338ms/epoch - 14ms/step\n",
            "Epoch 94/200\n",
            "24/24 - 0s - loss: 1.5917 - accuracy: 0.7639 - 127ms/epoch - 5ms/step\n",
            "Epoch 95/200\n",
            "24/24 - 0s - loss: 1.5059 - accuracy: 0.7951 - 315ms/epoch - 13ms/step\n",
            "Epoch 96/200\n",
            "24/24 - 0s - loss: 1.5277 - accuracy: 0.7720 - 136ms/epoch - 6ms/step\n",
            "Epoch 97/200\n",
            "24/24 - 0s - loss: 1.4968 - accuracy: 0.7870 - 129ms/epoch - 5ms/step\n",
            "Epoch 98/200\n",
            "24/24 - 0s - loss: 1.5005 - accuracy: 0.7680 - 125ms/epoch - 5ms/step\n",
            "Epoch 99/200\n",
            "24/24 - 0s - loss: 1.4213 - accuracy: 0.8073 - 149ms/epoch - 6ms/step\n",
            "Epoch 100/200\n",
            "24/24 - 0s - loss: 1.4436 - accuracy: 0.7910 - 126ms/epoch - 5ms/step\n",
            "Epoch 101/200\n",
            "24/24 - 0s - loss: 1.3882 - accuracy: 0.8073 - 125ms/epoch - 5ms/step\n",
            "Epoch 102/200\n",
            "24/24 - 0s - loss: 1.4454 - accuracy: 0.7558 - 135ms/epoch - 6ms/step\n",
            "Epoch 103/200\n",
            "24/24 - 0s - loss: 1.3686 - accuracy: 0.8073 - 125ms/epoch - 5ms/step\n",
            "Epoch 104/200\n",
            "24/24 - 0s - loss: 1.3578 - accuracy: 0.8100 - 128ms/epoch - 5ms/step\n",
            "Epoch 105/200\n",
            "24/24 - 0s - loss: 1.3226 - accuracy: 0.7992 - 318ms/epoch - 13ms/step\n",
            "Epoch 106/200\n",
            "24/24 - 0s - loss: 1.6491 - accuracy: 0.6201 - 124ms/epoch - 5ms/step\n",
            "Epoch 107/200\n",
            "24/24 - 0s - loss: 1.5476 - accuracy: 0.6757 - 119ms/epoch - 5ms/step\n",
            "Epoch 108/200\n",
            "24/24 - 0s - loss: 1.9237 - accuracy: 0.5007 - 123ms/epoch - 5ms/step\n",
            "Epoch 109/200\n",
            "24/24 - 0s - loss: 1.5318 - accuracy: 0.7028 - 118ms/epoch - 5ms/step\n",
            "Epoch 110/200\n",
            "24/24 - 0s - loss: 1.3772 - accuracy: 0.7653 - 121ms/epoch - 5ms/step\n",
            "Epoch 111/200\n",
            "24/24 - 0s - loss: 1.2779 - accuracy: 0.8318 - 118ms/epoch - 5ms/step\n",
            "Epoch 112/200\n",
            "24/24 - 0s - loss: 1.2673 - accuracy: 0.8128 - 124ms/epoch - 5ms/step\n",
            "Epoch 113/200\n",
            "24/24 - 0s - loss: 1.2053 - accuracy: 0.8236 - 134ms/epoch - 6ms/step\n",
            "Epoch 114/200\n",
            "24/24 - 0s - loss: 1.1926 - accuracy: 0.8236 - 124ms/epoch - 5ms/step\n",
            "Epoch 115/200\n",
            "24/24 - 0s - loss: 1.1323 - accuracy: 0.8630 - 117ms/epoch - 5ms/step\n",
            "Epoch 116/200\n",
            "24/24 - 0s - loss: 1.1786 - accuracy: 0.8250 - 317ms/epoch - 13ms/step\n",
            "Epoch 117/200\n",
            "24/24 - 0s - loss: 1.1209 - accuracy: 0.8521 - 128ms/epoch - 5ms/step\n",
            "Epoch 118/200\n",
            "24/24 - 0s - loss: 1.1460 - accuracy: 0.8412 - 306ms/epoch - 13ms/step\n",
            "Epoch 119/200\n",
            "24/24 - 0s - loss: 1.0816 - accuracy: 0.8602 - 118ms/epoch - 5ms/step\n",
            "Epoch 120/200\n",
            "24/24 - 0s - loss: 1.0493 - accuracy: 0.8806 - 137ms/epoch - 6ms/step\n",
            "Epoch 121/200\n",
            "24/24 - 0s - loss: 1.0311 - accuracy: 0.8711 - 126ms/epoch - 5ms/step\n",
            "Epoch 122/200\n",
            "24/24 - 0s - loss: 1.0124 - accuracy: 0.8752 - 125ms/epoch - 5ms/step\n",
            "Epoch 123/200\n",
            "24/24 - 0s - loss: 1.0288 - accuracy: 0.8765 - 118ms/epoch - 5ms/step\n",
            "Epoch 124/200\n",
            "24/24 - 0s - loss: 1.0076 - accuracy: 0.8684 - 119ms/epoch - 5ms/step\n",
            "Epoch 125/200\n",
            "24/24 - 0s - loss: 0.9878 - accuracy: 0.8833 - 116ms/epoch - 5ms/step\n",
            "Epoch 126/200\n",
            "24/24 - 0s - loss: 0.9590 - accuracy: 0.8901 - 132ms/epoch - 6ms/step\n",
            "Epoch 127/200\n",
            "24/24 - 0s - loss: 0.9696 - accuracy: 0.8697 - 121ms/epoch - 5ms/step\n",
            "Epoch 128/200\n",
            "24/24 - 0s - loss: 0.9735 - accuracy: 0.8752 - 127ms/epoch - 5ms/step\n",
            "Epoch 129/200\n",
            "24/24 - 0s - loss: 0.9655 - accuracy: 0.8697 - 120ms/epoch - 5ms/step\n",
            "Epoch 130/200\n",
            "24/24 - 0s - loss: 0.9323 - accuracy: 0.8874 - 126ms/epoch - 5ms/step\n",
            "Epoch 131/200\n",
            "24/24 - 0s - loss: 0.9145 - accuracy: 0.8806 - 117ms/epoch - 5ms/step\n",
            "Epoch 132/200\n",
            "24/24 - 0s - loss: 0.8954 - accuracy: 0.8874 - 120ms/epoch - 5ms/step\n",
            "Epoch 133/200\n",
            "24/24 - 0s - loss: 0.8950 - accuracy: 0.8860 - 118ms/epoch - 5ms/step\n",
            "Epoch 134/200\n",
            "24/24 - 0s - loss: 0.8764 - accuracy: 0.8942 - 310ms/epoch - 13ms/step\n",
            "Epoch 135/200\n",
            "24/24 - 0s - loss: 0.8645 - accuracy: 0.8915 - 122ms/epoch - 5ms/step\n",
            "Epoch 136/200\n",
            "24/24 - 0s - loss: 0.8434 - accuracy: 0.9037 - 395ms/epoch - 16ms/step\n",
            "Epoch 137/200\n",
            "24/24 - 0s - loss: 0.8433 - accuracy: 0.8996 - 170ms/epoch - 7ms/step\n",
            "Epoch 138/200\n",
            "24/24 - 0s - loss: 0.8408 - accuracy: 0.9023 - 474ms/epoch - 20ms/step\n",
            "Epoch 139/200\n",
            "24/24 - 0s - loss: 0.9310 - accuracy: 0.8480 - 169ms/epoch - 7ms/step\n",
            "Epoch 140/200\n",
            "24/24 - 0s - loss: 0.8512 - accuracy: 0.8969 - 185ms/epoch - 8ms/step\n",
            "Epoch 141/200\n",
            "24/24 - 0s - loss: 0.8214 - accuracy: 0.8928 - 167ms/epoch - 7ms/step\n",
            "Epoch 142/200\n",
            "24/24 - 0s - loss: 0.7918 - accuracy: 0.9091 - 473ms/epoch - 20ms/step\n",
            "Epoch 143/200\n",
            "24/24 - 0s - loss: 0.7764 - accuracy: 0.9159 - 184ms/epoch - 8ms/step\n",
            "Epoch 144/200\n",
            "24/24 - 0s - loss: 0.7637 - accuracy: 0.9118 - 178ms/epoch - 7ms/step\n",
            "Epoch 145/200\n",
            "24/24 - 0s - loss: 0.7743 - accuracy: 0.9118 - 188ms/epoch - 8ms/step\n",
            "Epoch 146/200\n",
            "24/24 - 0s - loss: 0.7489 - accuracy: 0.9199 - 191ms/epoch - 8ms/step\n",
            "Epoch 147/200\n",
            "24/24 - 0s - loss: 0.7328 - accuracy: 0.9240 - 474ms/epoch - 20ms/step\n",
            "Epoch 148/200\n",
            "24/24 - 0s - loss: 0.7217 - accuracy: 0.9281 - 192ms/epoch - 8ms/step\n",
            "Epoch 149/200\n",
            "24/24 - 0s - loss: 0.7408 - accuracy: 0.9104 - 462ms/epoch - 19ms/step\n",
            "Epoch 150/200\n",
            "24/24 - 0s - loss: 0.7723 - accuracy: 0.8779 - 127ms/epoch - 5ms/step\n",
            "Epoch 151/200\n",
            "24/24 - 0s - loss: 0.8064 - accuracy: 0.8806 - 136ms/epoch - 6ms/step\n",
            "Epoch 152/200\n",
            "24/24 - 0s - loss: 0.9579 - accuracy: 0.8114 - 130ms/epoch - 5ms/step\n",
            "Epoch 153/200\n",
            "24/24 - 0s - loss: 1.3657 - accuracy: 0.6201 - 133ms/epoch - 6ms/step\n",
            "Epoch 154/200\n",
            "24/24 - 0s - loss: 2.0601 - accuracy: 0.4491 - 121ms/epoch - 5ms/step\n",
            "Epoch 155/200\n",
            "24/24 - 0s - loss: 1.3458 - accuracy: 0.6906 - 337ms/epoch - 14ms/step\n",
            "Epoch 156/200\n",
            "24/24 - 1s - loss: 1.0010 - accuracy: 0.8209 - 690ms/epoch - 29ms/step\n",
            "Epoch 157/200\n",
            "24/24 - 0s - loss: 1.0178 - accuracy: 0.7965 - 133ms/epoch - 6ms/step\n",
            "Epoch 158/200\n",
            "24/24 - 0s - loss: 0.8552 - accuracy: 0.8738 - 128ms/epoch - 5ms/step\n",
            "Epoch 159/200\n",
            "24/24 - 0s - loss: 0.7641 - accuracy: 0.9050 - 123ms/epoch - 5ms/step\n",
            "Epoch 160/200\n",
            "24/24 - 0s - loss: 0.8014 - accuracy: 0.8697 - 120ms/epoch - 5ms/step\n",
            "Epoch 161/200\n",
            "24/24 - 0s - loss: 0.7551 - accuracy: 0.8874 - 120ms/epoch - 5ms/step\n",
            "Epoch 162/200\n",
            "24/24 - 0s - loss: 0.7111 - accuracy: 0.8915 - 120ms/epoch - 5ms/step\n",
            "Epoch 163/200\n",
            "24/24 - 0s - loss: 0.6605 - accuracy: 0.9132 - 122ms/epoch - 5ms/step\n",
            "Epoch 164/200\n",
            "24/24 - 0s - loss: 0.6589 - accuracy: 0.9267 - 123ms/epoch - 5ms/step\n",
            "Epoch 165/200\n",
            "24/24 - 0s - loss: 0.6296 - accuracy: 0.9322 - 131ms/epoch - 5ms/step\n",
            "Epoch 166/200\n",
            "24/24 - 0s - loss: 0.6413 - accuracy: 0.9308 - 136ms/epoch - 6ms/step\n",
            "Epoch 167/200\n",
            "24/24 - 0s - loss: 0.6397 - accuracy: 0.9064 - 120ms/epoch - 5ms/step\n",
            "Epoch 168/200\n",
            "24/24 - 0s - loss: 0.6109 - accuracy: 0.9199 - 125ms/epoch - 5ms/step\n",
            "Epoch 169/200\n",
            "24/24 - 0s - loss: 0.5933 - accuracy: 0.9240 - 124ms/epoch - 5ms/step\n",
            "Epoch 170/200\n",
            "24/24 - 0s - loss: 0.5870 - accuracy: 0.9281 - 124ms/epoch - 5ms/step\n",
            "Epoch 171/200\n",
            "24/24 - 0s - loss: 0.5797 - accuracy: 0.9349 - 120ms/epoch - 5ms/step\n",
            "Epoch 172/200\n",
            "24/24 - 0s - loss: 0.5807 - accuracy: 0.9294 - 127ms/epoch - 5ms/step\n",
            "Epoch 173/200\n",
            "24/24 - 0s - loss: 0.5770 - accuracy: 0.9294 - 132ms/epoch - 6ms/step\n",
            "Epoch 174/200\n",
            "24/24 - 0s - loss: 0.6085 - accuracy: 0.9118 - 121ms/epoch - 5ms/step\n",
            "Epoch 175/200\n",
            "24/24 - 0s - loss: 0.5833 - accuracy: 0.9308 - 139ms/epoch - 6ms/step\n",
            "Epoch 176/200\n",
            "24/24 - 0s - loss: 0.5706 - accuracy: 0.9267 - 120ms/epoch - 5ms/step\n",
            "Epoch 177/200\n",
            "24/24 - 0s - loss: 0.5515 - accuracy: 0.9322 - 126ms/epoch - 5ms/step\n",
            "Epoch 178/200\n",
            "24/24 - 0s - loss: 0.5337 - accuracy: 0.9403 - 129ms/epoch - 5ms/step\n",
            "Epoch 179/200\n",
            "24/24 - 0s - loss: 0.5270 - accuracy: 0.9430 - 314ms/epoch - 13ms/step\n",
            "Epoch 180/200\n",
            "24/24 - 0s - loss: 0.5202 - accuracy: 0.9376 - 123ms/epoch - 5ms/step\n",
            "Epoch 181/200\n",
            "24/24 - 0s - loss: 0.5479 - accuracy: 0.9294 - 135ms/epoch - 6ms/step\n",
            "Epoch 182/200\n",
            "24/24 - 0s - loss: 0.5202 - accuracy: 0.9444 - 120ms/epoch - 5ms/step\n",
            "Epoch 183/200\n",
            "24/24 - 0s - loss: 0.5129 - accuracy: 0.9498 - 120ms/epoch - 5ms/step\n",
            "Epoch 184/200\n",
            "24/24 - 0s - loss: 0.4996 - accuracy: 0.9471 - 127ms/epoch - 5ms/step\n",
            "Epoch 185/200\n",
            "24/24 - 0s - loss: 0.5451 - accuracy: 0.9376 - 121ms/epoch - 5ms/step\n",
            "Epoch 186/200\n",
            "24/24 - 0s - loss: 1.0135 - accuracy: 0.6866 - 332ms/epoch - 14ms/step\n",
            "Epoch 187/200\n",
            "24/24 - 0s - loss: 1.3521 - accuracy: 0.6974 - 132ms/epoch - 6ms/step\n",
            "Epoch 188/200\n",
            "24/24 - 0s - loss: 0.9562 - accuracy: 0.8182 - 131ms/epoch - 5ms/step\n",
            "Epoch 189/200\n",
            "24/24 - 0s - loss: 0.7236 - accuracy: 0.9104 - 127ms/epoch - 5ms/step\n",
            "Epoch 190/200\n",
            "24/24 - 0s - loss: 0.6580 - accuracy: 0.9118 - 124ms/epoch - 5ms/step\n",
            "Epoch 191/200\n",
            "24/24 - 0s - loss: 0.5721 - accuracy: 0.9308 - 122ms/epoch - 5ms/step\n",
            "Epoch 192/200\n",
            "24/24 - 0s - loss: 0.5281 - accuracy: 0.9430 - 130ms/epoch - 5ms/step\n",
            "Epoch 193/200\n",
            "24/24 - 0s - loss: 0.5132 - accuracy: 0.9484 - 166ms/epoch - 7ms/step\n",
            "Epoch 194/200\n",
            "24/24 - 0s - loss: 0.4885 - accuracy: 0.9484 - 120ms/epoch - 5ms/step\n",
            "Epoch 195/200\n",
            "24/24 - 0s - loss: 0.4764 - accuracy: 0.9512 - 125ms/epoch - 5ms/step\n",
            "Epoch 196/200\n",
            "24/24 - 0s - loss: 0.4748 - accuracy: 0.9552 - 328ms/epoch - 14ms/step\n",
            "Epoch 197/200\n",
            "24/24 - 0s - loss: 0.4590 - accuracy: 0.9539 - 129ms/epoch - 5ms/step\n",
            "Epoch 198/200\n",
            "24/24 - 0s - loss: 0.4536 - accuracy: 0.9525 - 127ms/epoch - 5ms/step\n",
            "Epoch 199/200\n",
            "24/24 - 0s - loss: 0.4413 - accuracy: 0.9620 - 147ms/epoch - 6ms/step\n",
            "Epoch 200/200\n",
            "24/24 - 0s - loss: 0.4336 - accuracy: 0.9593 - 124ms/epoch - 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f74c129fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
        "    init_word = current_word\n",
        "    sentence = ''\n",
        "\n",
        "    # n번 반복\n",
        "    for _ in range(n):\n",
        "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
        "\n",
        "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
        "        result = model.predict(encoded, verbose=0)\n",
        "        result = np.argmax(result, axis=1)\n",
        "\n",
        "        for word, index in tokenizer.word_index.items(): \n",
        "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "            if index == result:\n",
        "                break\n",
        "\n",
        "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "        current_word = current_word + ' '  + word\n",
        "\n",
        "        # 예측 단어를 문장에 저장\n",
        "        sentence = sentence + ' ' + word\n",
        "\n",
        "    sentence = init_word + sentence\n",
        "    return sentence\n",
        "print(sentence_generation(model, tokenizer2, \"봄이 오면\", 30))    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNID12LkfRri",
        "outputId": "17109106-2930-4bb6-d6f7-c7794586cc08"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "봄이 오면 마감 지 넬 맛은 나타났 때문이다 남북 같이 일본이 언 들이 쌀 밀 우리가 석 두어 맛 정도의 완전한 경쟁력을 경쟁력을 힘든 재무 공사 웹 휴 휴 날을 라이프 적절\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "origin= '봄이 오면 나무에는 파릇파릇한 싹이 돋아나고, 천지에 생명력이 가득하여 우리를 설레게 한다.\\n봄을 맞이하여 우리도 새로운 학교와 학급에서 새 친구들과 함께하는 즐거운 국어 시간을 통해 문학의 아름다움을 즐길 줄 아는 사람으로 성장할 것이다'\n",
        "origin.split(\" \")\n",
        "print(origin)\n",
        "sent = \"나무에는\"\n",
        "input_ids = tokenizer.encode(sent)\n",
        "print(type(input_ids))\n",
        "print(input_ids)\n",
        "while len(input_ids) < 30:\n",
        "    output = model(np.array([input_ids]))\n",
        "    # Top 5의 단어들을 추출\n",
        "    top5 = tf.math.top_k(output.logits[0, -1], k=1000)\n",
        "    # top5=top5[len(top5)-5:len(top5)]\n",
        "    k=tokenizer.convert_ids_to_tokens(top5.indices.numpy())\n",
        "    k=k[len(k)-6 :len(k)]\n",
        "    \n",
        "    for i in range(len(k)):\n",
        "      k[i]=tokenizer.encode(k[i])\n",
        "    \n",
        "    # Top 5의 단어들 중 랜덤으로 다음 단어로 선택.\n",
        "    token_id = random.choice(k)\n",
        "    input_ids.append(token_id[0])\n",
        "\n",
        "tokenizer.decode(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RnajfwCitIK",
        "outputId": "ebd7fa1c-5984-4465-f570-38d9030f9476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.ops.gen_nn_ops.TopKV2'>\n",
            "(<tf.Tensor: shape=(1000,), dtype=float32, numpy=\n",
            "array([11.5373535, 10.073083 ,  9.944405 ,  9.874777 ,  9.64585  ,\n",
            "        9.53906  ,  9.523936 ,  9.52004  ,  9.359821 ,  9.210946 ,\n",
            "        9.206393 ,  9.192377 ,  9.138684 ,  9.103445 ,  9.076993 ,\n",
            "        9.039064 ,  9.009724 ,  8.927725 ,  8.892429 ,  8.8671465,\n",
            "        8.842289 ,  8.772652 ,  8.768754 ,  8.737794 ,  8.734391 ,\n",
            "        8.734124 ,  8.730579 ,  8.721138 ,  8.68109  ,  8.613301 ,\n",
            "        8.607966 ,  8.595046 ,  8.564957 ,  8.562681 ,  8.555201 ,\n",
            "        8.533952 ,  8.518273 ,  8.480756 ,  8.46956  ,  8.455201 ,\n",
            "        8.402275 ,  8.400044 ,  8.334945 ,  8.31808  ,  8.314565 ,\n",
            "        8.296791 ,  8.2918215,  8.276949 ,  8.275611 ,  8.269139 ,\n",
            "        8.256231 ,  8.240455 ,  8.22493  ,  8.211713 ,  8.17937  ,\n",
            "        8.135791 ,  8.130085 ,  8.126602 ,  8.099544 ,  8.09632  ,\n",
            "        8.096167 ,  8.09265  ,  8.079878 ,  8.069183 ,  8.048207 ,\n",
            "        8.046988 ,  7.983058 ,  7.960332 ,  7.949538 ,  7.939814 ,\n",
            "        7.925125 ,  7.90527  ,  7.903142 ,  7.901498 ,  7.900548 ,\n",
            "        7.8761835,  7.847039 ,  7.8422656,  7.8325157,  7.8263326,\n",
            "        7.755285 ,  7.748891 ,  7.7467766,  7.741661 ,  7.7401414,\n",
            "        7.7069254,  7.702886 ,  7.701555 ,  7.699979 ,  7.691077 ,\n",
            "        7.6641154,  7.6621475,  7.6524286,  7.6436114,  7.643517 ,\n",
            "        7.593405 ,  7.580095 ,  7.5676804,  7.560521 ,  7.5578713,\n",
            "        7.556785 ,  7.543941 ,  7.543671 ,  7.542333 ,  7.5341296,\n",
            "        7.504691 ,  7.498269 ,  7.457547 ,  7.4572163,  7.453667 ,\n",
            "        7.4497843,  7.4484043,  7.4395585,  7.436865 ,  7.4338093,\n",
            "        7.424259 ,  7.4043555,  7.401817 ,  7.39963  ,  7.391224 ,\n",
            "        7.3561254,  7.3504744,  7.3395643,  7.33595  ,  7.3344693,\n",
            "        7.332214 ,  7.328031 ,  7.3268394,  7.3187222,  7.304299 ,\n",
            "        7.296209 ,  7.290279 ,  7.2887697,  7.2829547,  7.2614884,\n",
            "        7.249207 ,  7.247778 ,  7.2421975,  7.228252 ,  7.2226114,\n",
            "        7.221685 ,  7.217364 ,  7.2148275,  7.1846004,  7.1807046,\n",
            "        7.1794457,  7.178506 ,  7.175591 ,  7.1680217,  7.1478295,\n",
            "        7.1462173,  7.140952 ,  7.1394014,  7.136297 ,  7.135176 ,\n",
            "        7.1336737,  7.1335616,  7.130698 ,  7.128865 ,  7.1277137,\n",
            "        7.1275654,  7.1241684,  7.1015353,  7.10074  ,  7.0940666,\n",
            "        7.0860972,  7.0807915,  7.0787883,  7.070361 ,  7.0700045,\n",
            "        7.0663514,  7.0644417,  7.0643315,  7.060595 ,  7.0498495,\n",
            "        7.0449376,  7.0435596,  7.0423207,  7.0365353,  7.035031 ,\n",
            "        7.027252 ,  7.024375 ,  7.017515 ,  7.013247 ,  7.004052 ,\n",
            "        6.9968615,  6.9943576,  6.9848   ,  6.9835043,  6.9742727,\n",
            "        6.97321  ,  6.971394 ,  6.9637876,  6.9597096,  6.9579687,\n",
            "        6.95459  ,  6.943908 ,  6.939832 ,  6.9356027,  6.93348  ,\n",
            "        6.9290266,  6.921762 ,  6.9102216,  6.903941 ,  6.9010625,\n",
            "        6.9004183,  6.884958 ,  6.880897 ,  6.8745027,  6.8722506,\n",
            "        6.8580437,  6.8525753,  6.851431 ,  6.845436 ,  6.845095 ,\n",
            "        6.8446646,  6.8446236,  6.83554  ,  6.834682 ,  6.8298016,\n",
            "        6.823905 ,  6.81507  ,  6.806019 ,  6.8023467,  6.800411 ,\n",
            "        6.7930675,  6.7804174,  6.7797346,  6.765706 ,  6.7592845,\n",
            "        6.7562547,  6.754471 ,  6.7463784,  6.745071 ,  6.7439003,\n",
            "        6.7393317,  6.735293 ,  6.735123 ,  6.7278247,  6.7182765,\n",
            "        6.712929 ,  6.7127514,  6.7109947,  6.709943 ,  6.706259 ,\n",
            "        6.702366 ,  6.7010036,  6.691451 ,  6.6889844,  6.688938 ,\n",
            "        6.684933 ,  6.6848907,  6.683477 ,  6.6781063,  6.6728725,\n",
            "        6.6644773,  6.662115 ,  6.6579456,  6.657597 ,  6.6557226,\n",
            "        6.6531987,  6.6525216,  6.6494894,  6.649338 ,  6.647792 ,\n",
            "        6.647629 ,  6.646855 ,  6.64365  ,  6.6364193,  6.6329775,\n",
            "        6.6301055,  6.624827 ,  6.623838 ,  6.6149135,  6.6055036,\n",
            "        6.6045036,  6.6033792,  6.5968814,  6.59396  ,  6.591693 ,\n",
            "        6.590094 ,  6.589856 ,  6.586015 ,  6.5792475,  6.574982 ,\n",
            "        6.574683 ,  6.562744 ,  6.560267 ,  6.554569 ,  6.530383 ,\n",
            "        6.528283 ,  6.524003 ,  6.5209255,  6.51962  ,  6.5150766,\n",
            "        6.5144506,  6.5103154,  6.5088887,  6.508795 ,  6.5079446,\n",
            "        6.4984083,  6.49315  ,  6.4873724,  6.4869585,  6.475374 ,\n",
            "        6.475247 ,  6.4744053,  6.4701667,  6.467278 ,  6.466182 ,\n",
            "        6.4657927,  6.4628243,  6.462301 ,  6.4544883,  6.4418793,\n",
            "        6.437922 ,  6.4361753,  6.4278145,  6.426609 ,  6.4255567,\n",
            "        6.4222693,  6.415747 ,  6.4149137,  6.41061  ,  6.406178 ,\n",
            "        6.4010396,  6.3988576,  6.398253 ,  6.3955917,  6.3792834,\n",
            "        6.37067  ,  6.3658495,  6.3644395,  6.3584065,  6.3574543,\n",
            "        6.3563848,  6.350474 ,  6.3468432,  6.3465557,  6.346271 ,\n",
            "        6.3431125,  6.3411846,  6.3399305,  6.338023 ,  6.3367934,\n",
            "        6.336256 ,  6.334138 ,  6.331392 ,  6.32683  ,  6.323744 ,\n",
            "        6.3156676,  6.3135133,  6.311356 ,  6.3046246,  6.299316 ,\n",
            "        6.284429 ,  6.2809978,  6.2789574,  6.2774405,  6.268795 ,\n",
            "        6.2633014,  6.2569075,  6.2542214,  6.2488575,  6.247904 ,\n",
            "        6.246906 ,  6.2405295,  6.2347193,  6.226582 ,  6.2161036,\n",
            "        6.2122483,  6.2085476,  6.2070494,  6.1983943,  6.191181 ,\n",
            "        6.1899915,  6.1897964,  6.189248 ,  6.1891975,  6.188399 ,\n",
            "        6.184803 ,  6.183729 ,  6.182715 ,  6.176826 ,  6.176217 ,\n",
            "        6.1694436,  6.1685877,  6.167397 ,  6.164097 ,  6.151135 ,\n",
            "        6.150903 ,  6.1490746,  6.148864 ,  6.1482263,  6.142782 ,\n",
            "        6.1424108,  6.129458 ,  6.1245623,  6.1228647,  6.121187 ,\n",
            "        6.116161 ,  6.113317 ,  6.1090755,  6.1068673,  6.1012936,\n",
            "        6.0989604,  6.095814 ,  6.0940065,  6.0876727,  6.084531 ,\n",
            "        6.080383 ,  6.075187 ,  6.0742836,  6.073064 ,  6.0724697,\n",
            "        6.066779 ,  6.0552983,  6.051024 ,  6.049461 ,  6.047253 ,\n",
            "        6.0391045,  6.032607 ,  6.032394 ,  6.032328 ,  6.031604 ,\n",
            "        6.0269194,  6.0250483,  6.0147142,  6.0143733,  6.0130563,\n",
            "        6.009741 ,  6.0067444,  6.0066066,  6.0060077,  6.005098 ,\n",
            "        6.0050893,  6.002721 ,  6.0012484,  6.000427 ,  5.9946976,\n",
            "        5.986562 ,  5.9842324,  5.9829307,  5.982332 ,  5.974541 ,\n",
            "        5.9742584,  5.9735794,  5.9733577,  5.9700274,  5.966862 ,\n",
            "        5.963797 ,  5.9611073,  5.956724 ,  5.95302  ,  5.949565 ,\n",
            "        5.940412 ,  5.9367104,  5.935084 ,  5.9287634,  5.926729 ,\n",
            "        5.924095 ,  5.9208646,  5.9179196,  5.916203 ,  5.915872 ,\n",
            "        5.9147043,  5.9042573,  5.900525 ,  5.8935676,  5.8900537,\n",
            "        5.888526 ,  5.8880606,  5.8876686,  5.8836555,  5.883362 ,\n",
            "        5.882615 ,  5.8820357,  5.881212 ,  5.8805976,  5.8776317,\n",
            "        5.8751645,  5.8736367,  5.869644 ,  5.8678327,  5.860872 ,\n",
            "        5.857361 ,  5.8465247,  5.8432913,  5.842606 ,  5.8416243,\n",
            "        5.8348885,  5.8309875,  5.827583 ,  5.8271046,  5.826317 ,\n",
            "        5.824046 ,  5.818094 ,  5.8102913,  5.8054233,  5.8016677,\n",
            "        5.800716 ,  5.8002615,  5.7996264,  5.7990775,  5.7987504,\n",
            "        5.7926483,  5.7845325,  5.778924 ,  5.7753243,  5.7677207,\n",
            "        5.763379 ,  5.761676 ,  5.7605433,  5.757172 ,  5.75597  ,\n",
            "        5.755595 ,  5.7552   ,  5.74821  ,  5.7460403,  5.7439146,\n",
            "        5.7404413,  5.739409 ,  5.736275 ,  5.736025 ,  5.7348104,\n",
            "        5.7313786,  5.727977 ,  5.7246194,  5.724002 ,  5.7204556,\n",
            "        5.71017  ,  5.708216 ,  5.7080092,  5.7066646,  5.7053227,\n",
            "        5.7047925,  5.7034206,  5.7023735,  5.7011704,  5.7007184,\n",
            "        5.700119 ,  5.698861 ,  5.6982627,  5.6968894,  5.694996 ,\n",
            "        5.6845794,  5.684538 ,  5.6841455,  5.6808395,  5.6754885,\n",
            "        5.673957 ,  5.6661425,  5.6630454,  5.658433 ,  5.65643  ,\n",
            "        5.655047 ,  5.6525683,  5.650559 ,  5.6463   ,  5.6444736,\n",
            "        5.6410117,  5.6402245,  5.638935 ,  5.6377344,  5.637276 ,\n",
            "        5.636926 ,  5.635749 ,  5.624315 ,  5.6211305,  5.6188765,\n",
            "        5.6175776,  5.612721 ,  5.611405 ,  5.6110997,  5.610805 ,\n",
            "        5.606171 ,  5.6057434,  5.6051707,  5.6047764,  5.602764 ,\n",
            "        5.6011047,  5.597162 ,  5.595626 ,  5.592431 ,  5.587193 ,\n",
            "        5.5870185,  5.585902 ,  5.5849996,  5.5847588,  5.584191 ,\n",
            "        5.582797 ,  5.5808263,  5.578068 ,  5.576804 ,  5.574422 ,\n",
            "        5.5706735,  5.5695267,  5.5692677,  5.5500145,  5.5497026,\n",
            "        5.544238 ,  5.542822 ,  5.542337 ,  5.5423136,  5.5422926,\n",
            "        5.541102 ,  5.5410047,  5.54071  ,  5.540134 ,  5.538379 ,\n",
            "        5.5351615,  5.527691 ,  5.525681 ,  5.523377 ,  5.5227027,\n",
            "        5.5139794,  5.5127773,  5.510937 ,  5.510513 ,  5.5096865,\n",
            "        5.5092206,  5.5060143,  5.505179 ,  5.5039926,  5.4997573,\n",
            "        5.495865 ,  5.4956145,  5.487794 ,  5.4863324,  5.4855447,\n",
            "        5.4843087,  5.481631 ,  5.478866 ,  5.4767847,  5.4735   ,\n",
            "        5.470152 ,  5.4670906,  5.462446 ,  5.460057 ,  5.4540105,\n",
            "        5.453021 ,  5.451435 ,  5.4503016,  5.445856 ,  5.4440556,\n",
            "        5.4406505,  5.4383287,  5.4191027,  5.416224 ,  5.414333 ,\n",
            "        5.4136496,  5.4122944,  5.4105372,  5.4037476,  5.40277  ,\n",
            "        5.401471 ,  5.4014397,  5.4014106,  5.401172 ,  5.4000835,\n",
            "        5.399221 ,  5.392458 ,  5.3922205,  5.392215 ,  5.3855715,\n",
            "        5.384398 ,  5.380862 ,  5.380735 ,  5.379943 ,  5.3763175,\n",
            "        5.365783 ,  5.3653274,  5.3650956,  5.3645887,  5.3624315,\n",
            "        5.359581 ,  5.3551564,  5.3546977,  5.354603 ,  5.352881 ,\n",
            "        5.3526444,  5.352553 ,  5.3520694,  5.349999 ,  5.3495846,\n",
            "        5.348386 ,  5.3457737,  5.3447604,  5.3424454,  5.3331237,\n",
            "        5.332846 ,  5.3288264,  5.3275905,  5.3262672,  5.3255725,\n",
            "        5.322189 ,  5.3165307,  5.312621 ,  5.309824 ,  5.306838 ,\n",
            "        5.3060493,  5.3033004,  5.3009124,  5.298175 ,  5.296373 ,\n",
            "        5.2916903,  5.288347 ,  5.2882295,  5.277787 ,  5.2763925,\n",
            "        5.274727 ,  5.271726 ,  5.2710495,  5.270845 ,  5.2679353,\n",
            "        5.2671204,  5.2652855,  5.2640166,  5.2627788,  5.2625656,\n",
            "        5.2621694,  5.260048 ,  5.257987 ,  5.2561884,  5.2547603,\n",
            "        5.254535 ,  5.2492075,  5.2484994,  5.2464056,  5.2458773,\n",
            "        5.2430654,  5.242434 ,  5.241353 ,  5.2403936,  5.2377334,\n",
            "        5.2354016,  5.235048 ,  5.234954 ,  5.230608 ,  5.230306 ,\n",
            "        5.230075 ,  5.2264786,  5.224773 ,  5.2237434,  5.2133994,\n",
            "        5.211892 ,  5.2099056,  5.2050047,  5.2046847,  5.2038574,\n",
            "        5.202605 ,  5.1958547,  5.19473  ,  5.1935115,  5.1930556,\n",
            "        5.189846 ,  5.1867495,  5.179275 ,  5.177913 ,  5.1772847,\n",
            "        5.174636 ,  5.17101  ,  5.1647205,  5.1607614,  5.159214 ,\n",
            "        5.1586943,  5.1515937,  5.151241 ,  5.1507835,  5.1497064,\n",
            "        5.149076 ,  5.1471863,  5.146778 ,  5.142201 ,  5.1414413,\n",
            "        5.1401515,  5.1397834,  5.139616 ,  5.1385427,  5.137263 ,\n",
            "        5.136767 ,  5.1314564,  5.1271467,  5.123968 ,  5.1237345,\n",
            "        5.1236677,  5.1209946,  5.1194367,  5.1183167,  5.117412 ,\n",
            "        5.11519  ,  5.1122003,  5.1112695,  5.1091294,  5.108674 ,\n",
            "        5.1082473,  5.1044974,  5.10341  ,  5.1014743,  5.1000457,\n",
            "        5.099196 ,  5.0934896,  5.093054 ,  5.0917797,  5.0917397,\n",
            "        5.0869136,  5.084727 ,  5.0792704,  5.078124 ,  5.077441 ,\n",
            "        5.0745387,  5.0715165,  5.0708776,  5.0700336,  5.0695033,\n",
            "        5.069199 ,  5.055943 ,  5.055828 ,  5.0542526,  5.0521383,\n",
            "        5.0511675,  5.0506687,  5.0503035,  5.047135 ,  5.0439653,\n",
            "        5.0434785,  5.0416765,  5.040681 ,  5.039471 ,  5.038147 ,\n",
            "        5.0345106,  5.0329013,  5.0295525,  5.0270276,  5.0266213,\n",
            "        5.0236197,  5.0216546,  5.0202518,  5.017994 ,  5.0156193,\n",
            "        5.0146775,  5.012006 ,  5.0098176,  5.007596 ,  5.006496 ,\n",
            "        5.004766 ,  5.0020757,  4.999112 ,  4.997081 ,  4.995879 ,\n",
            "        4.9954486,  4.9941134,  4.9940534,  4.993415 ,  4.990179 ,\n",
            "        4.989908 ,  4.9893417,  4.987657 ,  4.9870434,  4.9863057,\n",
            "        4.9841294,  4.9830146,  4.9828267,  4.9799943,  4.979744 ,\n",
            "        4.9796944,  4.978835 ,  4.977431 ,  4.977297 ,  4.9763293,\n",
            "        4.9691925,  4.968399 ,  4.967414 ,  4.96433  ,  4.962995 ,\n",
            "        4.9615173,  4.9611545,  4.960975 ,  4.9585786,  4.957693 ,\n",
            "        4.943251 ,  4.9374213,  4.9338255,  4.9292054,  4.929058 ,\n",
            "        4.9253817,  4.9239144,  4.922468 ,  4.919897 ,  4.914757 ,\n",
            "        4.912505 ,  4.9122524,  4.9113836,  4.9109025,  4.908515 ,\n",
            "        4.9072495,  4.9063644,  4.905656 ,  4.905231 ,  4.9024563,\n",
            "        4.9004664,  4.9004283,  4.8967404,  4.8963127,  4.895908 ,\n",
            "        4.8957977,  4.894086 ,  4.8932595,  4.890329 ,  4.8877196,\n",
            "        4.8839803,  4.880114 ,  4.877729 ,  4.877654 ,  4.876988 ,\n",
            "        4.8754644,  4.875402 ,  4.8739104,  4.8714676,  4.8712783,\n",
            "        4.8688817,  4.868761 ,  4.8672915,  4.866355 ,  4.865544 ,\n",
            "        4.864815 ,  4.86155  ,  4.8603916,  4.85946  ,  4.858858 ,\n",
            "        4.8548374,  4.8533936,  4.848825 ,  4.8450465,  4.8437996,\n",
            "        4.843082 ,  4.8391047,  4.8379636,  4.8379416,  4.83709  ,\n",
            "        4.8339663,  4.820764 ,  4.818859 ,  4.8177238,  4.8177133,\n",
            "        4.8176103,  4.8112497,  4.8095875,  4.799368 ,  4.7976623,\n",
            "        4.795988 ,  4.7950044,  4.794043 ,  4.7907705,  4.788826 ,\n",
            "        4.7876363,  4.787003 ,  4.784319 ,  4.783909 ,  4.7838597,\n",
            "        4.783192 ,  4.77896  ,  4.7784786,  4.7767096,  4.7756486,\n",
            "        4.7753406,  4.7745943,  4.7736425,  4.7735105,  4.7734685,\n",
            "        4.7733192,  4.7720947,  4.7673616,  4.7649527,  4.7618394,\n",
            "        4.7609916,  4.757521 ,  4.7571816,  4.755271 ,  4.7533493,\n",
            "        4.7518377,  4.7515893,  4.751494 ,  4.7503896,  4.747964 ,\n",
            "        4.746886 ,  4.7461133,  4.744182 ,  4.7422776,  4.7403426,\n",
            "        4.7385707,  4.737474 ,  4.7371855,  4.7371783,  4.7363944,\n",
            "        4.735832 ,  4.734308 ,  4.733351 ,  4.7291245,  4.728902 ],\n",
            "      dtype=float32)>, <tf.Tensor: shape=(1000,), dtype=int32, numpy=\n",
            "array([ 7648, 13168, 23022,  8404,  8267, 15563,   382,  7198, 10335,\n",
            "       13565, 10076, 41400,  9063,  9026,  9769,  6945, 35630,  7492,\n",
            "        6866,  8187, 20182, 15178,  7058, 19925,  9791, 22007, 11770,\n",
            "       27771, 15527,  6884, 42069,  9752, 19020,  7767, 15768,  9301,\n",
            "        9429,  8213,  7120,  8368,  9413,  8745,  7791,  6831, 24636,\n",
            "       24127,  9054, 44629,  7423,  9050,  9072, 16402,  8037,  9203,\n",
            "        9524,  8747,  6898, 15528,  9060,  7609, 22441, 10739,  7848,\n",
            "        8159, 49150, 11565,  7610, 14458,  9059, 20004,  8220,  6918,\n",
            "        6886,  7071,  9538, 11244, 35870,  6958, 13539,  8615,  9819,\n",
            "        9181, 13232,  7847, 13429,  7258,  6905,  8694,   388, 15338,\n",
            "        9923, 10755,  7975, 12516,  9042, 14564, 10639,  6830,  9082,\n",
            "        6900, 10137,  7763, 40918, 14986,  9094,  8038,  8754, 10279,\n",
            "       36665,  8762, 42851,  9211, 25629,  8125, 23163,  9110,  9244,\n",
            "        9071, 17644,  9479, 14006, 11065,  8126,  7084, 10085, 43895,\n",
            "       15365, 14796,  7759,  9096,  9079,  7601,  9055,  7182,  9034,\n",
            "        9229,   739,  9417,  9242, 12410, 49481,  8264,  9649,  9065,\n",
            "       32940, 27580, 19437,  9803, 15171,  9117, 46453,  9174,  9228,\n",
            "       10391,  7824, 47733,  7487, 18062, 12920, 17903, 10313, 13847,\n",
            "        9070, 37353,  6954,  9025, 14222, 14162,  9741, 17201,  9183,\n",
            "       13405,  9135,  8131,  9194,  7607,  8381, 21449, 37811, 15846,\n",
            "        7671,  9032,  9166, 28706, 12141,  9152, 19577, 17196,  9440,\n",
            "        7584, 37173,  7056, 18471,  7586, 28874, 30953,  8756,  8346,\n",
            "        9467,  9815, 11138, 10553, 46762,  8265,  9018,  6893, 31281,\n",
            "        7540, 26578,  8168, 18744, 18268,  7483, 12509, 37239,  7185,\n",
            "       19190, 28179, 27930,  9226, 13651,  7066, 11432, 10252,  8797,\n",
            "       16910,  9208,  6935,  6879, 22097, 26235, 31891,  9081,  8149,\n",
            "       13628,  9358,  9067, 26595,  9114, 10133,  9093, 25688, 10337,\n",
            "        9202, 15253,  9726,  8006, 25705,  7982,  6826,  9073,  9421,\n",
            "       15252,  9722,  8091, 22646, 22408, 10445, 12735,  8740,  6912,\n",
            "       10297, 15017,  9037, 28305, 13235,  8033,  6908, 32511, 12479,\n",
            "        9099, 18324,  9924,  9943,  7055,  6951,   409,  7220, 23936,\n",
            "        9238, 10143,  8708, 10967,  8363, 16537, 12095,  7194,  6889,\n",
            "        7642, 10953,  8084,  9163, 10528, 27861, 29002, 24595,  7461,\n",
            "        8344, 10856, 11342,  9064, 43004, 15386,  9324,  9105,  9407,\n",
            "        9129,  7644,  8243,  8521,  6962,  9107, 10970, 32980,  6960,\n",
            "        9159,  8263, 22182, 12694,  9981,  8054,  9299,  7489,  7244,\n",
            "        8031,  9076,  7970,  9109,   426, 30867,  7597,  6875,  8608,\n",
            "        9140,  9235, 25653,  9218,  9351,  9077,  8148,  6877,  9410,\n",
            "       11685,  8796,  9942, 13337, 11154, 25696,  8570, 24563,  9043,\n",
            "         386,  7239,  7236, 13992, 10039,  9772, 15232, 16314, 11143,\n",
            "        8711, 10080, 44032,  8420,  7769,  8192,  9464, 12246, 13219,\n",
            "       21063, 21888,  9876,  7795, 22452, 44741, 12063, 12786, 10294,\n",
            "       16269, 28236,  9275, 42665, 32684, 24167,  7967, 16776, 10898,\n",
            "       10372,  7669, 40152, 23940, 10339,  8186, 25178, 24115, 37464,\n",
            "        9472,  8189,  9121, 10779,  9234, 12071, 10409,  9123,  6949,\n",
            "       10403, 39606,  9058, 20912,  7417, 36027, 10933,  9367, 14995,\n",
            "        8739, 22206,  9230, 13414,  9088, 43130, 12951,  9495, 20134,\n",
            "       13434, 10622, 12073, 19062, 11573, 13521,  7293, 18091,  9419,\n",
            "        8185, 23376,  8035,  9084,  8652, 35722,  8092, 15380, 17225,\n",
            "        9709,  9755, 21682,  9053,  8397,  9346, 14005,  9074, 15979,\n",
            "        9488,  8196, 18569,  7992,  7039, 27559, 19027, 24093, 15106,\n",
            "        9480,  9282, 10092,   452,  9345, 22587, 15028,  7890,  7235,\n",
            "        9644,  9523,  9266,  7884, 10249,  8400,  6853, 43730,  9623,\n",
            "       21924, 34049, 14124, 17569,  9280,  7541, 11634, 12163,  6963,\n",
            "       41498,  8806,  7109,  7773,  7660,  7501,  9680,  6919, 21308,\n",
            "       47521,  9746, 42614,  7692, 29158, 10308, 34221, 17554, 18225,\n",
            "       49986,  9703,   440,  7673,  9912,  8336, 10068, 49905,  6973,\n",
            "        9529, 27176,  9395, 33352,  9089,  9040,  9227, 10349,  7801,\n",
            "       15473,  7966, 14312, 12836,  8361,  8669, 25714, 48887, 12187,\n",
            "        9930, 21076, 13477, 16869, 11196, 11459,  8262, 38456,  9817,\n",
            "       10581,  8643,  9323,  9586, 23266,  9510, 40963,  8619,  9056,\n",
            "         454,  7488, 28686, 13533, 36640, 12250, 25086,  7123,  8774,\n",
            "       33404, 11494, 36144,  9804,  9260, 19216,  9184, 14712,  7643,\n",
            "       24869, 11141,  9384, 29024,  9259,  9300,  9408,  8335,  9141,\n",
            "       19144,  7480, 13828,  9707, 30871, 11061,  7304,  9095, 10949,\n",
            "        8548, 11528, 33277,  8563, 39309, 12147,  7588, 33952,  9390,\n",
            "        8194,  9296, 34884,  9219, 31238, 10524,  9231,  7825,  8052,\n",
            "       13041, 40865,  8749,  6953, 11427,  7478,  8170,  9265,  7596,\n",
            "       10632, 17402, 47171,  7444, 15813, 13220, 10105,  7521,  7788,\n",
            "        7799,  7907, 35750,   408, 23069,  9673,  9206,  7131,  7177,\n",
            "        7575, 17738, 23415, 16384, 18840,  9435,  7561, 10896,  9232,\n",
            "       40466,  9729,  7559,  8758, 12382, 11613, 28383, 13678, 11913,\n",
            "       41133, 23941, 33974, 11316, 40955, 10073, 10084, 47343,  9252,\n",
            "       30651, 12213, 34708,  9297, 20014, 16476,  6828, 30475,  8519,\n",
            "        9024, 43075,  7265, 47529,  9578, 50725,  9967, 11396,  9193,\n",
            "        8337,  9454, 46753, 49579, 15369,  7107,  8339, 22837,  8618,\n",
            "       10088, 26222, 26383,   430, 32354,  7965, 11574, 11236, 11781,\n",
            "       10321,  9652, 15676, 19541, 33106,  9125,   389, 31941, 19618,\n",
            "       25528, 13472, 15317,  7119,  8360,  7060, 44995,  9730, 18808,\n",
            "       10238,  6825, 15089, 13344, 40247, 11925, 13294,  9928,  7957,\n",
            "       13385, 12096,   445,  9664,  8024,  8217,  9195,  7849,  9138,\n",
            "        6848, 21054, 38265, 47036, 47708, 31272, 10757, 33215,  6855,\n",
            "       19842,  9632,  9122, 27225, 16896, 10174,  8030,  9546, 14692,\n",
            "       10768, 14337,  9518,  9049,  9169, 15715,  7599,  9214, 39579,\n",
            "       50194,  9044, 45399, 28596, 17516, 11270, 16180,  9818, 23330,\n",
            "       45085, 13961, 40909, 12512, 25113, 25059,  9648,  8658,  8236,\n",
            "       26384,  8152, 14835, 15264,  9185,  9502, 13570, 19257, 10048,\n",
            "       13600,  9318, 38399,  9382, 24988,  6904, 44955, 11207, 41889,\n",
            "        8078,  9098, 12537, 18129, 33077, 16826,  9728, 19645,  7172,\n",
            "        9281,  9841, 13899, 11704,  8239, 10152,  8068, 26116,  7426,\n",
            "       13203,  8721, 19567,  7888, 11329,  9256,  8600, 49857,  7062,\n",
            "         468,  9453, 10951, 13077,  9633,  9319, 12940,  8804,  9921,\n",
            "       34353, 10197, 11780,  9118, 14931, 46266, 19671, 30034, 11197,\n",
            "        9580, 16541,  8105,  9425,  8418,  9145, 16793, 34259, 35317,\n",
            "       10187, 34986, 12753, 18059, 27984,  7536, 32915, 31317, 17714,\n",
            "        7555,  9112,  9192, 15967,  9725,  9264,  9719,  6835,  9352,\n",
            "       16080, 10535, 46885,  8508, 10307, 17874,  8074,  7744, 13417,\n",
            "       10114,  6841, 10058, 37169, 45997, 13312, 31354,   433,  9066,\n",
            "       13257,  9128, 47324,  8710, 48199, 21564,  8104, 11281, 23025,\n",
            "        9274, 10446, 12546, 21000,  9103,  6921, 11778, 20072, 18810,\n",
            "       14993, 47280,  9267, 38340, 12918, 40238, 12619,  9091,  9621,\n",
            "       11671, 17586, 17000,  8423, 17408, 30768, 21470, 16720, 12427,\n",
            "        8626, 19447,  9175, 11949, 29309,  7427, 24699, 14828, 19457,\n",
            "       20226,  7892, 20971, 44630, 10498, 13346, 18257, 25497,  7625,\n",
            "       10199, 30353,  9596, 39419, 19633, 29621, 10401, 27281,     5,\n",
            "        7502,  8467, 15255,  9544,  7532,  9199, 10169, 32916, 11926,\n",
            "       10996, 16809, 26166, 12354, 16059, 10367,  9142, 31654,  9215,\n",
            "        9873, 40949, 26849, 15329,  8529, 16605,  8422,  7397, 19946,\n",
            "       10464, 11278, 24523, 31520, 41159, 10489, 14509, 27913,  9694,\n",
            "       41562,   413, 12225,  7983, 51143,  8702,  8679, 29272, 15330,\n",
            "       29946,  7836,  8094, 21459, 18130,  9478, 16001, 10437,  8474,\n",
            "       16973], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '당신은 말을 할 수 있습니까?'\n",
        "with torch.no_grad():\n",
        "  # tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
        "  gen_tokens = model.generate(tokens,     \n",
        "    do_sample=True, #샘플링 전략 사용\n",
        "    max_length=50, # 최대 디코딩 길이는 50\n",
        "    top_k=50, # 확률 순위가 50위 밖인 토큰은 샘플링에서 제외\n",
        "    top_p=0.95, # 누적 확률이 95%인 후보집합에서만 생성\n",
        "    num_return_sequences=2, #2개의 결과를 디코딩해낸다\n",
        "  )\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "print(generated)  "
      ],
      "metadata": {
        "id": "g674qEDBSye-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59168d01-16ea-46ce-8647-bd41f8d48f74"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "당신은 말을 할 수 있습니까?\"\n",
            "\"그렇습니다. 하지만 그건 아닙니다.\"\n",
            "\"그렇다면 그건 아닙니다.\"\n",
            "\"그렇다면 그건 아닙니다.\"\n",
            "\"그렇다면 그건 아닙니다.\"\n",
            "\"그렇다면\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m_sV_jv0bkUL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y73CVOLfTI-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beam Search 기반 "
      ],
      "metadata": {
        "id": "XtXTcJzJblR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''당신은 AI입니다. 정말로 '언어'를 이해합니까?'''\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(\n",
        "      tokens, \n",
        "      max_length=100, \n",
        "      num_beams=5, #1보다 큰 값을 지정\n",
        "      no_repeat_ngram_size=2, # 2-gram의 어구가 반복되지 않도록 설정함\n",
        "      num_return_sequences=5, # 다섯 개의 문장을 리턴\n",
        "      early_stopping=True #EOS토큰이 나오면 생성을 중단\n",
        "  )\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "print(generated)  \n"
      ],
      "metadata": {
        "id": "CRBqhqThSwZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UztvyrLsNUeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sampling 기반"
      ],
      "metadata": {
        "id": "W7RdXeIpcL1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''당신은 AI입니다. 정말로 '언어'를 이해합니까?'''\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(\n",
        "      tokens, \n",
        "      max_length=100, \n",
        "      do_sample=True, #샘플링 전략 사용\n",
        "      top_k=50, # 확률 순위가 50위 밖인 토큰은 샘플링에서 제외\n",
        "      top_p=0.95, # 누적 확률이 95%인 후보집합에서만 생성\n",
        "      temperature= 0.75,# sharpness 조절 낮으면 shaprness 증가 randomness 감소 \n",
        "      num_return_sequences=3 #3개의 결과를 디코딩해낸다\n",
        "  )\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "print(generated)  \n"
      ],
      "metadata": {
        "id": "7sMf9GktT8Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mtrx7Vy7T-_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dH-spsfvT_br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ll8rDXpkUg4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R_At7LyuUmob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- open-ended 생성에서는 top-k 확은 top-p 디코딩이 greedy 혹은 beam search보다 좋은 전략일 수 있다.\n",
        "\n",
        "- 하지만 안타깝게도 top-k / top-p 샘플링 전략도 동어 반복 문제는 있다. (논문)\n",
        "\n",
        "- 게다가, 모델의 훈련 목적 함수를 잘 조절하면 beam-search가 더 유창한 텍스트를 생성한다는 연구도 있다. (논문)\n",
        "\n",
        "- 이는 open-ended 생성이 최근 빠르게 발전하는 연구분야인만큼, 어떤 하나의 전략이 \"무조건 좋다\"라고 말하기 어렵기 때문. \n",
        "\n",
        "- 포스팅에서 소개한 다양한 방법을 실험해보며 사용자의 태스크에 적합한 전략을 선택하는 것이 중요하다."
      ],
      "metadata": {
        "id": "mTQ1GJBcUuKP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VERsZWY4UtjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "요즘은 흔히 연락하라는 말을 '카톡해'라고 하지만 10년전 카카오톡이 등장하기 전까지는 '문자해'라는 말이 일반적이었다. MSN 메신저, 네이트온 등 PC 메신저들이 유행해 '메신저'라는 개념에는 익숙했지만 스마트폰 도입이 갓 시작됐을 시기라 모바일 메신저 개념은 희미했다.\n",
        "모바일을 통한 연락 수단이 전화와 문자 메시지였기 때문에 통신사 요금제 역시 통화 가능 시간과 문자의 갯수에 따라 달려졌다. 문자 한 건당 비용이 책정되는데다 70자가 넘으면 MMS로 전환돼 추가 요금이 부가돼 이용자들은 문자 전송에도 한땀한땀 정성을 다해야 했다.\n",
        "때문에 당시 카카오톡의 등장은 센세이션 그 자체였다. 유료 문자메시지를 당연하게 사용했던 시절 글자 제한없는 문자를 무제한으로 보낼 수 있는데다 사진과 동영상까지 마음껏 전송할 수 있는 무료서비스 카카오톡은 문화 충격이나 다름 없었다.\n",
        "문자뿐 아니라 통화 문화도 변했다. 2012년 당시 가입자가 3600만명에 달했던 카카오톡이 무료 음성통화 서비스 '보이스톡'을 선보이자 통신업계가 떠들썩해졌다. 카카오 보다 앞서 음성 통화 서비스를 선보인 마이피플, 라인 등은 크게 주목받지 못했지만 카카오톡은 높은 이용자수를 기반으로 보이스톡 서비스를 확장시켰다.\n",
        "특히 보이스톡은 로밍 서비스에 가입하거나 국제 전화 서비스를 이용하지 않아도 데이터만 연결돼 있다면 해외에서도 카카오톡 친구와 무료 통화가 가능하다는 점 때문에 큰 화제를 모았다. 이때부터 해외 여행 시 로밍을 하지 않고 현지 유심을 구매하는 이들이 늘어나게 됐다.\n",
        "\n",
        "한줄 요약:'''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(\n",
        "      tokens, \n",
        "      max_length=50, \n",
        "      num_beams=5, #1보다 큰 값을 지정\n",
        "      no_repeat_ngram_size=2, # 2-gram의 어구가 반복되지 않도록 설정함\n",
        "      num_return_sequences=5, # 다섯 개의 문장을 리턴\n",
        "      early_stopping=True #EOS토큰이 나오면 생성을 중단\n",
        "  )\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "InAxLGaczGbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "\n",
        "다음 문장을 서울 말투에서 북한 말투로 말투를 변환 합니다. \n",
        "\n",
        "서울 말투 : 배고파요, 우리 저기서 뭐라도 먹고갈까요?\n",
        "\n",
        "북한 말투 : '''\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(\n",
        "      tokens,\n",
        "      do_sample=True, #샘플링 전략 사용\n",
        "      max_length=80, # 최대 디코딩 길이는 50\n",
        "      top_k=50, # 확률 순위가 50위 밖인 토큰은 샘플링에서 제외\n",
        "      top_p=0.95, # 누적 확률이 95%인 후보집합에서만 생성\n",
        "      temperature= 0.75,\n",
        "      num_return_sequences=3 #3개의 결과를 디코딩해낸다\n",
        "  )\n",
        "  generated = tokenizer.batch_decode(gen_tokens)\n",
        "  \n",
        "print(generated[0])"
      ],
      "metadata": {
        "id": "EkTTmQCB4P0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "Translate the Korean sentence into English sentence \n",
        "Korean : \"나 지금 많이 배고픈데, 우리 저기서 뭐라도 먹고갈까?\"\n",
        "English : \"'''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  #두 전략을 섞어서 사용하면, 너무 낮게 랭킹된 토큰을 사용하는 것은 피하면서도 꽤나 다양한 시퀀스를 생성할 수 있다.\n",
        "\n",
        "  sample_outputs = model.generate(\n",
        "      tokens,\n",
        "      do_sample=True, #샘플링 전략 사용\n",
        "      max_length=70, # 최대 디코딩 길이는 50\n",
        "      top_k=50, # 확률 순위가 50위 밖인 토큰은 샘플링에서 제외\n",
        "      top_p=0.95, # 누적 확률이 95%인 후보집합에서만 생성\n",
        "      temperature= 0.65,\n",
        "      num_return_sequences=3 #3개의 결과를 디코딩해낸다\n",
        "  )\n",
        "    \n",
        "  generated = tokenizer.batch_decode(sample_outputs)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "llkl6MAW5weK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xJFioYlTdh93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "최고 핫한 인공지능, kogpt님과 인터뷰 나눠보겠습니다!\n",
        "Q : kogpt님, 수월한 대화가 가능하신가요?\n",
        "A : '''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(\n",
        "      tokens, \n",
        "      max_length=100, \n",
        "      num_beams=5, #1보다 큰 값을 지정\n",
        "      no_repeat_ngram_size=2, # 2-gram의 어구가 반복되지 않도록 설정함\n",
        "      num_return_sequences=5, # 다섯 개의 문장을 리턴\n",
        "      early_stopping=True #EOS토큰이 나오면 생성을 중단\n",
        "  )\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "_0Uiu5PGDPd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "최고 핫한 인공지능, kogpt님과 인터뷰 나눠보겠습니다!\n",
        "Q : kogpt님, 수월한 대화가 가능하신가요?\n",
        "A : '''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  gen_tokens = model.generate(\n",
        "      tokens, \n",
        "      max_length=100, \n",
        "      do_sample=True, #샘플링 전략 사용\n",
        "      top_k=50, # 확률 순위가 50위 밖인 토큰은 샘플링에서 제외\n",
        "      top_p=0.95, # 누적 확률이 95%인 후보집합에서만 생성\n",
        "      temperature= 0.75,# sharpness 조절 낮으면 shaprness 증가 randomness 감소 \n",
        "      num_return_sequences=3 #3개의 결과를 디코딩해낸다\n",
        "  )\n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "OCtHApN0divr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "최고 핫한 인공지능, kogpt님과 인터뷰 나눠보겠습니다!\n",
        "Q : kogpt님, 수월한 대화가 가능하신가요?\n",
        "A : '''\n",
        "\n",
        "with torch.no_grad():\n",
        "  tokens = tokenizer.encode(prompt, return_tensors='pt').to(device='cuda', non_blocking=True)\n",
        "  #gen_tokens = model.generate(tokens, do_sample=True, temperature=0.85, max_length=128)\n",
        "  gen_tokens = model.generate(\n",
        "      tokens,\n",
        "      do_sample=True, #샘플링 전략 사용\n",
        "      max_length=256, # 최대 디코딩 길이는 50\n",
        "      top_k=50, # 확률 순위가 50위 밖인 토큰은 샘플링에서 제외\n",
        "      top_p=0.95, # 누적 확률이 95%인 후보집합에서만 생성\n",
        "      temperature= 0.85,\n",
        "      num_return_sequences=3 #3개의 결과를 디코딩해낸다\n",
        "  )\n",
        "    \n",
        "  generated = tokenizer.batch_decode(gen_tokens)[0]\n",
        "  \n",
        "print(generated)"
      ],
      "metadata": {
        "id": "v4LWtqxtXi30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtfctbGlX8lf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}